\documentclass{article}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{array}
\usepackage{booktabs}

\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}
\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\title{\includegraphics[width=4cm]{./Images/LOGO.pdf} \par\noindent\huge{Instruction Set Architecture}}
\date{17/04/2022}
\author{Enrico Gatto Monticone}

\begin{document}

    \pagenumbering{arabic}
	\maketitle
	\newpage
%__________________________________________________________________________________________________________________________________

	\tableofcontents
    \listoftables
	\newpage
%__________________________________________________________________________________________________________________________________

    \section[Introduction]{\LARGE\underline{Introduction}} % 1

        \vspace{10pt}

        FabRISC is a feature rich, register-register, load-store architecture with variable length encodings of two, four and six bytes. This specification is designed to be highly modular allowing a simple and straightforward implementation from basic designs up to high performance systems by picking only the desired modules. The ISA includes scalar, vector, floating-point, compressed, atomic as well as privileged instructions supporting 32 and 64-bit multithreaded microarchitectures. It is also possible to further enrich and enhance the ISA by allocating unused opcode combinations to custom application specific instructions. This specification is completely free, open-source and available to anyone interested in the project via the official GitHub: xxx (license details can be found at the very end of the document). The specification is divided into multiple sections each explaining the architecture in detail with the help of tables, figures and implementation specific suggestions in order to aid the hardware and software designers in creating an efficient realization of the FabRISC instruction set architecture.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Commentary in this document will formatted in this way and communication will be more colloquial. If the reader is only interested in the specification, these sections can be skipped without hindering the understanding of the document. This project tries to be more of a hobby learning experience rather than a new super serious industry standard, plus the architecture borrows many existing concepts from the most popular and iconic ISAs like x86, RISC-V, MIPS, ARM and openRISC. I chose to target FPGAs as the primary platform for two main reasons: one is that ASICs are out of the question for me and most people because of cost. Two is that using discrete components makes little sense from a sanity and practicality point of view given the complexity of the project, however, software simulators can be a good platform for simpler implementations. The core ideas here are the use of variable length encoding of four and six byte instruction size along with an optional compressed module to increase code density. Another aspect of the ISA is the fact that all instructions can specify the length of the data type in order to more precisely control edge cases such as overflows and underflows as well as orthogonality reasons. This is not achieved via register sub addressing but rather by simply masking the unnecessary portion of the word while leaving the ignored bits in place. This ISA, all though not a ``pure'' RISC design with basic instructions and few addressing modes, resembles that philosophy for the most part skewing away from it in specific (and optional) areas only, such as, being able to load, store, move and swap multiple registers with a single instruction.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection[Terminology]{Terminology}

            \vspace{10pt}

            The FabRISC architecture uses the following terminology throughout the document in order to more accurately define technical concepts and vocabulary:

            \begin{itemize}

                \item \textit{\textbf{``Architecture''} is used to refer to the set of abstractions that the hardware must provide to the software.}

                \item \textit{\textbf{``Atomic''} is used to refer to any operation that must, either be completely executed, or not at all.}

                \item \textit{\textbf{``Architectural state''} is used to refer to the state of the processor, or a single core or hardware thread, that can directly be observed by the programmer.}

                \item \textit{\textbf{``Coherence''} is used to refer to the ability of a system to be coherent, that is, ensuring the uniformity of shared resources across the entire system. In particular, it defines the ordering of accesses to a single memory location for systems that implement caching techniques.}

                \item \textit{\textbf{``Consistency''} is used to refer to the ability of a system to be consistent, that is, defining a particular order of operations across all memory locations that is obeyed by everyone within the system.}

                \item \textit{\textbf{``Consistency model''} is used to refer to a particular model or protocol of consistency within a particular system.}

                \item \textit{\textbf{``Core''} is used to refer to a fully functional and complete sub-CPU within a bigger entity. Advanced processors often aggregate multiple similar sub-CPUs in order to be able to schedule different programs each working on it's own stream of data. It is important to note that each core can implement a completely different microarchitecture, as well as, instruction set.}

                \item \textit{\textbf{``Event''} is used to generically refer to any extra-ordinary situation that needs to be taken care of as soon as possible.}

                \item \textit{\textbf{``Exception''} is used to refer to any non severe internal, synchronous event.}

                \item \textit{\textbf{``Fault''} is used to refer to any severe internal, synchronous event.}

                \item \textit{\textbf{``Hardware thread''} or simply \textbf{``hart''} are used to refer to a particular physical instance of a software thread running, specifically, on the central processing unit (CPU).}

                \item \textit{\textbf{``Instruction set architecture''} or simply \textbf{``ISA''} are used to refer to the architecture that the central processing unit provides to the software under the form of instructions.}

                \item \textit{\textbf{``Interrupt''} is used to refer to any external, asynchronous event.}

                \item \textit{\textbf{``Memory fence''} or simply \textbf{``fence''} are used to refer to particular instructions that have the ability to enforce a specific ordering of other memory instructions.}

                \item \textit{\textbf{``Memory transaction''} or simply \textbf{``transaction''} are used to refer to a particular series of operations that behave atomically within the system.}

                \item \textit{\textbf{``Microarchitectural state''} is used to refer to the actual state of the processor, or a single core or hardware thread, that might not be visible by the programmer in its entirety.}

                \item \textit{\textbf{``Microarchitecture''} is used to refer to the particular physical implementation of a given architecture.}

                \item \textit{\textbf{``Page''} is used to refer to a logical partition of the main system memory.}

                \item \textit{\textbf{``Promotion''} is used to refer to the automatic switch from user mode to supervisor mode by the processor or a single core or hardware thread, caused by an event.}

                \item \textit{\textbf{``Transparent''} is used to refer to something that is, mostly, invisible to the programmer.}

                \item \textit{\textbf{``Trap''} is used to refer to the transition from a state of normal execution to the launch of an event handler.}

                \item \textit{\textbf{``Unaligned''} or \textbf{``misaligned''} are used to refer to any memory item that is not naturally aligned, that is, the address of the item modulo its size, is not equal to zero.}

            \end{itemize}

        \subsection[Implementation specific parameters]{Implementation specific parameters}

            \vspace{10pt}

            This document also makes use of some implementation specific microarchitecture parameters to clear potential misunderstandings:

            \begin{itemize}

                \item \textit{\textbf{Word Length} (WLEN): this parameter indicates the processor's natural scalar word length in bits, for example, a 64-bit CPU will have WLEN of 64.}

                \item \textit{\textbf{Maximum Vector Length} (MXVL): this parameter indicates the processor's maximum vector length in bits. Possible values can be chosen from:}

                    \begin{itemize}

                        \item \textit{64 bit: for processors with WLEN of 32.}
                        \item \textit{128 bit: for processors with WLEN of 32 and 64.}
                        \item \textit{256 bit: for processors with WLEN of 32 and 64.}
                        \item \textit{512 bit: for processors with WLEN of 64.}

                    \end{itemize}

            \end{itemize}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{I consider 512 bits for 64 bit machines and 256 for 32 bit machines to be a good maximum limit since i doubt that even advanced architectures would benefit in a practical way from a wider vector pipeline except, perhaps, in some very specific situations. This length can already be a bit of a challenge because of the shear width, necessitating a very large number of bits for the reservation station entries in out-of-order machines. Other than a practical limit, there is also a physical limit to the vector length which is given by the length of the vector mask register (VMSK) in the special purpose register file. This is because VMSK must be VLEN bits wide which, in the case of 64 bit machines can allocate up to 64 mask bits (one per byte element). The same logic applies for 32 bit machines which are limited to 32 mask bits.}
        \par\noindent\rule{\textwidth}{0.4pt}

    \clearpage

%__________________________________________________________________________________________________________________________________

    \section[Memory]{\LARGE\underline{Memory}} % 2

        \vspace{10pt}

        This section is dedicated to the memory model used by FabRISC including data alignment, synchronization, consistency, as well as possible cache coherence directives. All primitive data types must have one of the following sizes:

        \begin{itemize}

            \item \textit{\textbf{Byte}: a grouping of continuous 8 bits.}
            \item \textit{\textbf{Short}: a grouping of continuous 16 bits.}
            \item \textit{\textbf{Word}: a grouping of continuous 32 bits.}
            \item \textit{\textbf{Doubleword}: a grouping of continuous 64 bits (for 64 bit machines only).}

        \end{itemize}

        \subsection[Data alignment]{Data alignment}

            \vspace{10pt}

            FabRISC, overall, treats the main memory and the MMIO regions as collections of byte-addressable locations in \textit{little endian} order with a range of \(2^{WLEN}\) addresses in total. The specification leaves to the hardware designer the choice of supporting aligned or unaligned memory accesses or both for data. If aligned is decided to be the only supported scheme, the hart must generate the MISA fault every time the constraint is violated (consult section 4 for more information). When it comes to instructions, it's mandatory to have fetch engines that support accesses at the 16-bit boundary alignment. This is because the greatest common denominator of the instruction sizes, with or without compressed instructions, is 16 and the programmer must ensure that the code is aligned at said boundary, if not, the MISI fault must be generated. Branch offsets, as a result of this, are logically shifted by one place to the left before being added to the program counter (PC). This means that said offsets will specify 16-bits as the smallest addressable object, effectively doubling the range in terms of bytes.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Data alignment issues can arise when the processor wants to read or write an item whose size is greater than the smallest addressable thing. This problem is tricky to design hardware for, especially caches, because misaligned items can cross cache line boundaries as well as page boundaries. Alignment networks and more complex caches are needed which can increase complexity and slow down the critical path too much for simple designs. For already complex multicore out-of-order superscalar machines, however, i believe that supporting unaligned accesses can be handy so that the software writer can make decisions freely without having to worry about this problem, potentially decrease the memory footprint.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Synchronization}

            \vspace{10pt}

            FabRISC provides dedicated atomic instructions to achieve proper synchronization in order to protect critical sections and to avoid data races in threads that share memory with each other. The proposed instructions behave atomically and can be used to implement atomic \textit{read-modify-write} and \textit{test-and-set} operations for locks, semaphores and barriers. It is important to note that if the processor can only run one hart at any given moment, then this section can be skipped since the problem can be solved by the operative system. Below is a description of the atomic instructions, which are divided in two categories:

            \begin{itemize}

                \item \textit{\textbf{Read-modify-write} instructions:}

                \begin{itemize}

                    \item \textit{\textbf{Load Linked} (LL) is an atomic memory operation that loads an item from memory into a register and performs a ``reservation'' of the fetched location. The reservation can simply be storing the physical address and size of the object into an internal transparent register marking it as valid.}

                    \item \textit{\textbf{Store Conditional} (SC) is an atomic instruction that stores an item from a register to a memory location if and only if the reservation matches and is marked as valid, that is, the physical address and size are the same plus the valid bit set. In the case of a mismatch, or an invalidity, SC must not perform the store and must return a zero in its destination register as an indication of the failure. If SC succeeds, the item is written to memory, a one is returned into its register destination and all reservations must be then invalidated.}

                \end{itemize}

                \item \textit{\textbf{Test-and-set} instructions:}

                \begin{itemize}

                    \item \textit{\textbf{Compare and swap} (CAS) is an atomic instruction that conditionally and atomically swaps two values in memory if a particular and specified condition is met. The conditions are equality or less than.}

                \end{itemize}

            \end{itemize}

            FabRISC also provides optional instructions to support basic transactional memory that can be employed instead of the above seen solutions to exploit parallelism in a more ``optimistic'' manner. Multiple transactions can happen in parallel as long as no conflict is detected by the hardware. when such situations occur, however, the offended transaction must be aborted, that is, it must discard all the changes and restore the architectural state immediately before the start of the transaction itself. If a transaction detects no conflict it is allowed to commit the changes and the performed operations can be considered atomic. Transactions can be nested inside each other up to a depth of 256, beyond this, the OABT exception must be generated to notify the programmer.

            \begin{itemize}

                \item \textit{\textbf{Transaction Begin} (TBEG): causes the hart that executed this instruction to checkpoint its microarchitectural state and start monitoring accesses by other harts via the coherence protocol as well as incrementing the nesting counter by one. This instruction effectively starts a transaction.}

                \item \textit{\textbf{Transaction End} (TEND): causes the hart that executed this instruction to stop monitoring accesses by other harts and commit the changes as well as decrementing the nesting counter by one. This instruction effectively terminates a transaction. The updates to memory can be considered atomic and permanent after the completion of this instruction.}

                \item \textit{\textbf{Transaction Abort} (TABT): causes the hart that executed this instruction to stop monitoring accesses by other harts as well as generate an \textbf{Explicit abort} exception within the hart and cause it to restore the microarchitectural state immediately before the latest TBEG as well as decrementing the transaction nesting level counter by one. This instruction effectively aborts a transaction.}

                \item \textit{\textbf{Transaction Check} (TCHK): causes the hart that executed this instruction to return, in a specified register, the status of the current running transactional execution. This instruction effectively checks if the thread is in a transaction as well as its depth.}

            \end{itemize}

            Transactions can generate exceptions, as briefly mentioned above, called \textit{abort codes} that can be used by the programmer to take the appropriate actions in case the transaction was aborted. Each abort code specifies the reason why the current (most nested) transaction was aborted.

            \begin{itemize}

                \item \textit{\textbf{Conflict abort} (CABT): the current transaction was aborted because a write on shared variables was detected by the coherence protocol.}

                \item \textit{\textbf{Event abort} (EABT): the current transaction was aborted because an event, beside the ones in this list, got triggered.}

                \item \textit{\textbf{Depth overflow abort} (OABT): the current transaction was aborted because it exceeded the upper transaction depth limit.}

                \item \textit{\textbf{Replacement abort} (RABT): the current transaction was aborted because a cache line was evicted back to memory for not enough associativity.}

                \item \textit{\textbf{Size abort} (SABT): the current transaction was aborted because a cache line was evicted for back to memory not enough space.}

                \item \textit{\textbf{Depth underflow abort} (UABT): this abort code is only generated if a TEND instruction is executed and the depth counter is zero.}

            \end{itemize}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Memory synchronization is extremely important in order to make shared memory communication even work at all. The problem arises when a pool of data is shared among different processes or threads that compete for resources and concurrent access to this pool might result in erroneous behavior and must, therefore, be arbitrated. This zone is called ``critical section'' and special atomic primitives can be used to achieve this protection. Many different instruction families can be chosen such as ``compare-and-swap'', ``test-and-set'', ``Read-modify-write'' and others. I decided to provide in the ISA the LL and SC pairs, as described above, because of its advantages and popularity among other RISC-like instruction sets. Two important advantages of this pair is that it is pipeline friendly (LL acts as a load and SC acts as a store) compared to others that try to do both. Another advantage is the fact that the pair doesn't suffer from the ``ABA'' problem. It is important to note, however, that this atomic pair doesn't guarantee forward progress and weaker implementations can reduce this chance even more. The CAS atomic instruction, even though it suffers from the ABA problem, it guarantees forward progress, rendering this instruction stricter. I decided to also provide basic transactional memory support because, in some situations, it can yield great performance compared to mutual exclusion without losing atomicity. This is completely optional and up to the hardware designer to implement or not simply because it can significantly complicate the design. Transactional memory seems to be promising in improving performance and ease of implementation when it comes to shared memory programs, but debates are still ongoing to decide which exact way of implementing is best.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Coherence}

            \vspace{10pt}

            FabRISC leaves to the hardware designer the choice of which coherence system to implement. On multicore systems cache coherence must be ensured by choosing a coherence protocol and making sure that all the cores agree on the current sequence of accesses to the same memory location. That can be guaranteed by serializing the operations via the use of a shared bus or via a distributed directory and \textit{write-update} or \textit{write-invalidate} protocols can be employed without any issues. Software coherence can also be a valid option but it will rely on the programmer to explicitly flush or invalidate the cache of each core separately. Nevertheless, FabRISC provides implementation-dependent instructions, such as CACOP, that can be sent to the cache controller directly to manipulate its operation (see section 7 for more details). If the processor makes use of a separate instruction cache, potential complications can arise for self modifying code which can be solved by employing one of the above options. All the harts that map to the same core don't need to worry about coherence since the caches are shared between those harts. This argument holds true for whole cores that share bigger pools of cache, such as L2 or L3.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Cache coherence is a big topic and is hard to get right because it can hinder performance in both single core and multicore significantly. I decided to give as much freedom as possible to the designer of the system to pick the best solution that they see fit. Another aspect that could be important, if the software route is chosen, is the exposure to the underlying microarchitecture implementation to the programmer which can be yield unnecessary complications and confusions. Generally speaking though write-invalidate seems to be the standard approach in many modern designs because of the way it behaves in certain situations, especially when a process is moved to another core. Simple shared bus can be a good choice if the number of cores is small (lots of cores means lots of traffic), otherwise a directory based approach can be used to ensure that all the cores agree on the order of accesses. From this, the protocol can be picked: MSI, MESI, MOSI or MOESI, the latter being the most complex but most powerful.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Consistency}

            \vspace{10pt}

            FabRISC utilizes a fully relaxed memory consistency model formally known as \textit{release consistency} that allows all possible orderings in order to give harts the freedom to reorder memory instructions to different addresses in any way they want. For debugging and specific situations the stricter \textit{sequential consistency} model can be utilized and the hart must be able to switch between the two at any time via a dedicated bit in the control and status register. Special instructions, called \textit{``fences''}, are provided to let the programmer impose an order on memory operations when the relaxed model is in use. If the hart doesn't reorder memory operations this section can be skipped. The proposed fencing instructions are:

            \begin{itemize}

                \item \textit{\textbf{Fence Loads} (FNCL): this instruction forbids the hart to reorder any load type instruction across the fence.}

                \item \textit{\textbf{Fence Stores} (FNCS): this instruction forbids the hart to reorder any store type instruction across the fence.}

                \item \textit{\textbf{Fence Loads and Stores} (FNCLS): this instruction forbids the hart to reorder any load or store type instructions across the fence.}

            \end{itemize}

            The fences can be used on any memory type of instruction, including the LL \& SC pair and CAS to forbid reordering when acquiring or releasing a lock for critical sections and barriers. Writes to portions of memory where the code is stored can be made effective by issuing a command to the cache controller via the special implementation specific CACOP instruction as briefly discussed above.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{The memory consistency model i wanted to utilize was a very relaxed model to allow all kinds of performance optimization to take place inside the system. However one has to provide some sort of restrictions, effectively special memory operations, to avoid absurd situations. Even with those restrictions debugging could be quite difficult because the program might behave very weirdly, so i decided to include the sequential model that forbids reordering of any kind of memory instruction. If a program is considered well synchronized (data race-free and all critical sections are protected) consistency becomes less of an issue because there will be no contention for resources and, therefore, the model can be completely relaxed without any side effects. Achieving this level of code quality is quite the challenge and so these consistency instructions can be employed in making sure that everything works out.}
        \par\noindent\rule{\textwidth}{0.4pt}

    \clearpage

%__________________________________________________________________________________________________________________________________

    \section[Input Output]{\LARGE\underline{Input Output}} % 3

        \vspace{10pt}

        This section is dedicated to the specification that FabRISC uses for communicating with external devices as well as other cores and hardware threads if present. The architecture defines IO mappings, potential DMA behavior and, in the next section, OS support and inter-process communication schemes are discussed.

        \subsection{Memory mapped IO}

            \vspace{10pt}

            FabRISC reserves a portion of the high memory address space to \textit{memory mapped IO}. This region, of the size of $2^{16}$ bytes, is not cached nor paged and byte addressable in little-endian order. If a hart wants to transfer data to an IO device it can simply execute a memory operation to this section without further complications. The IO device must map all of its internal registers and state to this region and multiple channels or buses can potentially be employed to reduce the latency in case another transfers are already taking place as well as increasing the bandwidth. It is important to note that this region, is not paged in the traditional sense, that is, the virtual to physical mapping will always be the same, however it must still have page table entries for protection bits. The ISA splits this MMIO address space in two segments:

            \begin{itemize}

                \item \textit{\textbf{CPU segment}: this portion, starting from address zero, is composed of 128 bytes and should be used to hold CPU information, such as implemented ISA extensions, cache sizes as well as other CPU capabilities and characteristics.}

                \item \textit{\textbf{IO segment}: this portion, starting from address 128, is composed of 65408 bytes and should be used to communicate with external devices via MMIO.}

            \end{itemize}

            \vspace{10pt}
            \input{./Tables/CPU_segment_table.tex}
            \vspace{10pt}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{I decided to go with memory mapped IO because of its flexibility and simplicity compared to port based solutions. The IO region can be considered plain memory by the processor internally, which allows for advanced and fancy operations that use locks, barriers, fences and transactions to be done by multiple threads to the same device. I don't recommend caching or paging this region because it can yield potential inconsistencies and unnecessary complexities. This region still needs page table entries because of the protection bits, however, i suggest leaving the mappings of virtual to physical the same all the time for simplicity.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Direct memory access}

            \vspace{10pt}

            FabRISC provides the ability for IO devices to access the main system memory directly via DMA without passing through the processor. A dedicated centralized controller can be utilized to achieve this, but the hardware designer is free to choose another alternative if considered appropriate and, if this method of communication is chosen to be used, cache coherence must be ensured between the processor and the IO devices too. Some possible options can be, as discussed earlier:

            \begin{itemize}

                \item \textit{\textbf{Non cacheable memory region}: with this configuration coherence isn't a problem because no caching is performed by the CPU and the IO device in question. The system, however, needs to be able to dynamically declare which portion of memory is cacheable and which isn't which can lead to unnecessary complexities.}

                \item \textit{\textbf{Software IO coherence}: with this configuration the CPU and the device are required to flush or invalidate the cache explicitly with no extra hardware complexity, however, this option requires the exposure of the underlying organization to the programmer.}

                \item \textit{\textbf{Hardware IO coherence}: with this configuration, both the CPU and the IO device, will monitor each other's accesses via a common bus or a directory and proper actions are automatically taken according to a coherence protocol which can be the already existent one in the processor.}

            \end{itemize}

            The DMA protocol or scheme implemented by the hardware designer must also take consistency into account since memory operations to different addresses are allowed to be done out-of-order. This means that fencing instructions must retain their effect from the point of view of the hart and IO devices, which must provide similar fencing features as well.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{For more bandwidth demanding devices, DMA can be used to transfer data at very high speeds in the order of several Gb/s without interfering with the CPU. This scheme however, is more complex than plain MMIO because of the special arbiter that handles and grants the requests. IO coherence, as well as its consistency, is actually the main reason of this subsection as a remainder that it needs to be considered during the development of the underlying microarchitecture, including the devices themselves.}
        \par\noindent\rule{\textwidth}{0.4pt}

    \clearpage
%__________________________________________________________________________________________________________________________________

    \section[Events]{\LARGE\underline{Events}} % 4

        \vspace{10pt}

        This section is dedicated to the specification of exceptions, faults and interrupts. FabRISC uses the term \textit{event} to indicate the generic categorization of these kinds of situations. Events can be used to communicate with other harts, processes, IO devices, signal system faults or simply trigger software exceptions. Events are sub divided into two main categories: Synchronous and Asynchronous.

        \subsection{Synchronous}

            \vspace{10pt}

            Synchronous events are internally generated and are considered deterministic, that is, if they happen, they will always happen in the same location of the executing program and, because of this, the handling must done in program order. This category is further sub divided in two.

            \begin{itemize}

                \item \textit{\textbf{Exceptions}: These events are user handled, non promoting and with a global priority level of 0. They are generated by the executing instructions and each process can have it's own private handler with the help of a dedicated pointer register. From a higher level, the handling of exceptions looks like an automatic function call to the specified handler address.}

                \item \textit{\textbf{Faults}: These events are supervisor handled, promoting and with a global priority level of 2. They are generated by the executing instructions and each process will have the same handler specified by the supervisor. From a high level, the handling of faults looks like an automatic function call performed by the supervisor to a location that is always the same and then branching, usually under the form of a case statement, to the proper code.}

            \end{itemize}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Exceptions and faults are used to identify software related problems and edge cases such as overflows, divisions by zero, memory accesses to protected sections and more. I believe that exceptions can be valuable and useful for handling special cases quickly and preemptively without having to perform time consuming checks over and over. Examples of this can be seamless array boundary checks via the use of debugging registers (see section 6 for more information) that trigger the appropriate exception. Arithmetic edge cases can be similarly treated via the use of said special registers or by operating the processor in a ``safe state'', which will trigger the appropriate exception every time something went wrong with the executing software. Faults are similar to exceptions but for more delicate problems such as page faults, illegal or malformed instructions and accesses to protected memory areas. All in all, i believe that one cannot really design a hardware system where these kinds of problems never occur, which is why i put emphasis on being able to gracefully recover when such cases happen.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Asynchronous}

            \vspace{10pt}

            Asynchronous events are externally generated and are not considered deterministic, that is, they can happen at any time regardless of what the CPU is doing. Asynchronous events can be masked but only by the supervisor and should be handled as soon as possible in order to keep latency low. This category is further sub divided in two.

            \begin{itemize}

                \item \textit{\textbf{IO interrupts}: These events are supervisor handled, promoting with a global priority level of 3. They are generated by external IO devices and can have an internal priority level to decide which one to handle when multiple are triggered at the same time. From a high level, the handling of IO interrupts, can be considered as a context switch to the desired process that will handle the device request, which can be achieved in a similar fashion to faults.}

                \item \textit{\textbf{IPC interrupts}: These events are supervisor handled, promoting with a global priority level of 1. They are generated by other harts in the system in order to communicate with each other (inter-process communication) and can have an internal priority level to decide which one to handle when multiple are triggered at the same time. From a high level, the handling of IPC interrupts, can be considered as a context switch to the desired process that will handle the IPC request, which can be achieved in a similar fashion to faults and IO interrupts.}

            \end{itemize}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{I think that interrupts are a great tool that allow the IO devices themselves to start the communication, as opposed to the time consuming polling. This option is especially useful when low latency is required and can be used in conjunction with the regular low speed memory mapped IO transfers or the faster DMA. For devices that do not need any kind of bandwidth or responsiveness, polling can still be a valid choice without utilizing any extra resources. A shadow register file can potentially be utilized to reduce the latency to a minimum, however, it must behave transparently to the programmer.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Event handling}

            \vspace{10pt}

            Handling events involves a \textit{``launching''} phase and a \textit{``returning''} phase. The steps of each phase must be performed by the trapped hart in a single cycle in order to avoid potential corruption of its internal state. The launching phase is composed of the following parallel steps:

            \begin{enumerate}

                \item \textit{write the event identifier into the cause register (CAUSE).}

                \item \textit{save the value of the program counter (PC) and status register (CSR) into the appropriate buffer registers depending on the privilege level of the event:}

                    \begin{itemize}

                        \item \textit{for non-promoting events, simply copy the PC into the exception buffer 0 (EB0) and the CSR into the user exception buffer 1 (UEB1).}

                        \item \textit{for promoting events, simply copy the PC, into the supervisor event buffer 0 (SEB0), the CSR into the supervisor event buffer 1 (SEB1) and the CAUSE register into the supervisor event buffer 2 (SEB2). The reason for the copy of the cause register is to avoid state corruption since the currently interrupted hart might already be handling an exception.}

                    \end{itemize}

                \item \textit{mask any other interrupt if the triggered event is promoting, otherwise skip this step. The masking can be accomplished by simply setting the xxx and xxx bits in the CSR to one.}

                \item \textit{set the xxx bit of the CSR to one in order to signify that the hart is handling an event.}

                \item \textit{switch to supervisor mode if the triggered event is promoting by setting the xxx bit in the CSR, otherwise skip this step.}

                \item \textit{jump to the handler location with the use of the appropriate pointer register. Depending of the privilege level of the event this step will involve:}

                    \begin{itemize}

                        \item \textit{for non-promoting events, a simple copy of the value of the user event handler pointer (UEHP) into the program counter suffices. From there a case statement can be used in combination with the CAUSE register to determine which event was generated.}

                        \item \textit{for promoting events, a simple copy of the value of the supervisor event handler pointer (SEHP) into the program counter suffices. From there a case statement can be used in combination with the CAUSE register to determine which event was generated.}

                    \end{itemize}

            \end{enumerate}

            After the execution of the desired handler code, the last instruction will trigger the returning phase. During that phase, it is sufficient to restore the value of the program counter, the status register and, if the event was promoting, the CAUSE register by storing into them the values of the appropriate buffer registers previously written. It is important to note that the processor must always trap preemptively, that is, before the trapping instruction writes the result and, after the return phase, the processor must replay the instruction that caused the event.

            \vspace{10pt} 

            Global priority, introduced in the previous subsections, is used to give a further discriminant in case different types of events are triggered in the same clock cycle. Events with global priority level of 3 will be considered first, all the way to priority level 0. Local priority simply specifies the order in which events of the same type must be handled. Local priority concerns asynchronous events only, since synchronous events must be handled in program order as discussed in the previous sections.

            \vspace{10pt}

            Performance counters must be freezed if the triggered event is promoting. If the supervisor needs the performance monitoring counters, it must save them first before unfreezing them. The supervisor must restore the proper values of the counters before actually scheduling a user process for execution. This ensures the retention of values across context switches and event handling.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Handling events should be quite a straight forward process. The launching phase explains all the needed steps to successfully branch to the target location. Once the handler is executed the ERET instruction can be executed to bring back the old state. This mechanism can be used to schedule another process entirely, by setting all the registers to the desired values and executing an ERET instruction which causes the PC and CSR to be written with the values held in the supervisor event buffers. When an event of any kind is triggered, it's necessary to flush or invalidate any in-flight instruction including the very last stage (write-back / commit). This is because it's possible to perform (absolute) branches by simply writing to the program counter directly with a standard move instruction, which means that the control flow can erroneously be steered back causing the execution of wrong instructions if the last stage is left unaltered.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \vspace{10pt}
        \input{./Tables/Supervisor_event_table.tex}
        \vspace{10pt}
        \input{./Tables/User_event_table.tex} % gotta finish
        \vspace{10pt}

    \clearpage
%__________________________________________________________________________________________________________________________________

    \section[OS support]{\LARGE\underline{OS support}} % 5

        \vspace{10pt}

        This section is dedicated to the supported OS primitives by the FabRISC architecture. They are divided into different categories explained below and should be, ideally, handled by the hardware in order to give the operative system a solid foundation. The features allow the realization of any kind of OS, from \textit{monolithic} designs, \textit{microkernel}, \textit{exokernel} and hybrids.

        \subsection{Supervisor mode}

            \vspace{10pt}

            FabRISC is a privileged architecture and makes use of the supervisor to create a border between the OS and the user. With supervisor privileges the executing code has complete and total control over the hardware and any access to protected resources in user mode, such as particular instructions, registers, or addresses must generate the appropriate fault. The hart should only enter the supervisor mode if an appropriate event is triggered and a dedicated instruction (ERET) is provided to transfer the control back to the user (consult section 7 for more information). If the system makes use of a multicore / multithreaded processor, then each core must have the ability to be in supervisor mode or not independently.

            \vspace{10pt}

            When booting up, the system should start in supervisor mode with only one core active to allow the loading of the OS itself and the creation of all the required data structures. This is indicated by the xxx bit in the status register. After the booting phase is done, this bit can simply be set to zero causing the processor to execute normally.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Having a supervisor mode is essential for implementing a working operative system. This special mode allows the executing code to have complete and total control over the CPU and is used, by the OS, to protect itself from other processes that could, intentionally or not, compromise the system. When the processor isn't running in supervisor mode it will run in user mode with restrictions, mainly in manipulating certain hardware state including some special registers, addresses and instructions. This, along with virtual memory, will effectively confine any user level process to its own sandbox protecting itself and others from damage.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Virtual memory}

            \vspace{10pt}

            FabRISC provides privileged customizable and implementation specific instructions to interface directly with the MMU, if the processor has one, allowing the OS to modify and manage that particular unit (see section 7 for more details), alternatively, the managing can be automatic if the hardware supports it. A special purpose register called PTP is also provided to hold the physical address of the page table to perform the page table walk in case of a TLB miss. PTP must be set by the supervisor only with the appropriate address every time a context switch happens and a write operation on PTP in user mode must cause a fault. The TLB can also make use the process ID in the PID register to avoid flushing during context switches and page swapping can be supported via the generation of the \textit{page fault} event that can be handled by the OS.

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Virtual memory is a central concept in any operative system and i wanted to provide, at least, basic support without going too crazy (this is pretty much as simple as it gets). The CSR also has a special bit to enable or disable paging by bypassing the TLB and avoid doing the virtual to physical translation all together. The process ID can help reducing the burst of TLB misses caused by context switches especially with frequent system calls in microkernel based solutions.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Hardware thread communication}

            \vspace{10pt}

            Thanks to the already discussed IPC interrupts, it is possible to implement efficient low level hardware thread communication. Initialization and termination of threads, however, is mandatory since it effectively allows the creation and destruction of threads if the processor has multiple cores or threads. With IPC interrupts it possible to perform:

            \begin{itemize}

                \item \textit{\textbf{Thread signalling}: this form of communication is achieved by the use of dedicated interrupts as suggested earlier. The signal can be sent to an IO controller just like a request from an external IO device which can then forward the request to the destination thread that is interrupted.}

                \item \textit{\textbf{Message passing}: this form of communication is achieved by the use of dedicated MMIO addresses to send and receive small messages through the IO controller. The message formats should use a common convention agreed by the hardware designer and the programmer for everybody.}

                \item \textit{\textbf{Thread initialization} and \textbf{Thread termination}: this form of communication is vital to be able to start and stop threads at will in multicore / multithreaded systems. Starting a thread can be achieved by sending a dedicated IPC interrupt that has the ability to wake up the destination core or hardware thread from the halted state. A similar and symmetric picture can employed to stop running cores or threads via a dedicated halting IPC interrupt. An alternative would be to directly talk to the IO controller, which in turn, enables or disables threads.}

            \end{itemize}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{Efficient communication is key to achieve good performance in any system. I decided to support simple message passing and signalling directly in hardware to lower the latencies as much as possible since an FPGA CPU will only have clock speeds in the hundreds of MHz. The only form of communication that isn't explicitly listed here is ``shared memory'' simply because it is a natural consequence of virtual memory and paging. In this subsection i assumed the presence of a centralized IO controller that manages interrupts, IO requests, data transfers as well as thread initialization and termination. Any other solution that behaves similarly to that is completely possible and allowed, for example a more distributed kind of controller where each core has its own independent logic (or something along those lines) could be a possible alternative.}
        \par\noindent\rule{\textwidth}{0.4pt}

    \clearpage
%__________________________________________________________________________________________________________________________________

    \section[ISA specification]{\LARGE\underline{ISA specification}} % 6

        \vspace{10pt}

        In this section the register file organization, vector model, processor modes and the ISA modules are presented. FabRISC is a modular ISA composed of four macro modules each divided into several micro modules that the hardware designer can choose. The macro modules concern computational, data transfer, control transfer and system instructions:

        \begin{itemize}

           \item \textit{\textbf{Computational}: this macro module contains all the instructions that perform arithmetic or logic operations.}

                \begin{itemize}

                    ...

                \end{itemize}

           \item \textit{\textbf{Data transfer}: this macro module contains all the instructions that perform data transfer operations.}

                \begin{itemize}

                    ...

                \end{itemize}

           \item \textit{\textbf{Jumps}: this macro module contains all the instructions that perform control transfer operations.}

                \begin{itemize}

                   ...

                \end{itemize}

           \item \textit{\textbf{System}: this macro module contains all the instructions that perform specific system operations.}

                \begin{itemize}

                    ...

                \end{itemize}

        \end{itemize}

        Processors that don't support certain modules must generate the xxx fault whenever an unimplemented instruction is fetched. Processors must also generate the xxx fault whenever a combination of all zeros or all ones is fetched in order to increase safety against buffer overflows exploits or uninitialized locations. 

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{To indicate which ISA modules a particular implementation is composed of, a simple binary number can be used similarly to a checklist. FabRISC allows the hardware designer to choose any combination of micro module, however, for each macro module at least one micro module must be chosen. With this is perfectly legal, for example, to have almost no scalar instructions rendering the underlying processor a potential vector-heavy machine.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Register file}

            \vspace{10pt}

            Depending on which modules are chosen as well as WLEN and MXVL values, the register file can be composed of up to three different banks of variable width. Registers are declared in the following presented lists in order:

            \begin{enumerate}

                \item \textit{\textbf{Scalar general purpose registers} (SGPRs): this bank is composed of 32 registers which can be used to hold program variables during execution. The registers are all WLEN bits wide and are used by scalar integer and floating point instructions. All of these registers are non privileged.}

                \item \textit{\textbf{Special purpose registers} (SPRs): this bank is composed of 32 registers which are internally used to keep track of state, modes, flags and other system related things. The registers can be WLEN or 32 bits wide with some being privileged resources.}

                \item \textit{\textbf{Vector general purpose registers} (VGPRs): this bank is composed of 32 registers which can be used for holding values during execution. The registers are all MXVL bits wide and are used by vector integer and floating point instructions. This bank is only necessary if the machine in question supports vector execution. All of these registers are non privileged.}

            \end{enumerate}

            % TWEAK THE LOOK OF THE TABLE
            \vspace{10pt}
            \input{./Tables/Register_file.tex}
            \vspace{10pt}

            \subsubsection{Register ABI}

                \vspace{10pt}

                FabRISC specifies an ABI (application binary interface) for the SGPRs and VGPRs. It is important to note that this is just a suggestion on how the general purpose registers should be used in order to increase code compatibility. For scalar registers:

                \begin{itemize}

                    \item \textit{\textbf{Parameter registers}: registers prefixed with the letter 'P' are used for parameter passing and returning to and from function calls. Parameters are stored in these registers starting from the top-down, while returning values are stored starting from the bottom-up.}

                    \item \textit{\textbf{Persistent registers}: registers prefixed with the letter 'S' are ``persistent'' registers, that is, registers whose value should be retained across function calls. This implies a ``callee save'' calling convention for these registers.}

                    \item \textit{\textbf{Volatile registers}: registers prefixed with the letter 'N' are ``volatile'' registers, that is, registers whose value may not be retained across function calls. This implies a ``caller save'' calling convention for these registers.}

                    \item \textit{\textbf{Global pointer} (GP): this register is used to point to the global variable area.}
                    \item \textit{\textbf{Stack pointer} (SP): this register is used as a pointer to the call-stack.}
                    \item \textit{\textbf{Return address} (RA): this register is used to hold the return address for the currently executing function call.}

                \end{itemize}

                Vector registers are all considered persistent, which means that the callee save scheme must be utilized since it's assumed that their value will be retained across function calls. Special instructions are also provided to move vector registers, or part of them, to and from the scalar bank (see section 7 for more information).

            \subsubsection{Special purpose register bank}

                \vspace{10pt}

                The special purpose register bank, as mentioned earlier, is composed or 32 registers of different width with a specific purpose in mind. It is important to note that multiple registers may be updated every cycle, which means that, this bank should be seen more as a grouping of independent registers rather than an actual file. The SPRs are organized as follows:

                \begin{itemize}

                    \item \textit{\textbf{Debugging registers}: registers prefixed with ``DBG'' are used for debugging and other support features such as real-time counters and performance metrics. If DBG registers are not used for any specific purpose, they can be used as extra scalar GPRs in which the ABI categorizes them as extra volatile registers. DBG registers are all WLEN bits wide and are not privileged. It's worth noting that when used as counters, DBG registers will only be real-time for the current running process.}

                    \item \textit{\textbf{Debugging mode registers}: registers prefixed with ``DBGM'' are used to specify the particular operating mode of the DBG registers (see table below for more information). Each DBG register has a six bit code reserved in its corresponding DBGM register to indicate the operating mode. Registers DBG0 to DBG4 will map to DBGM0 while registers DBG5 to DBG9 will map to DBGM1. All DBGM registers are always 32 bits wide and are not privileged.}

                    \item \textit{\textbf{Exception buffers}: registers prefixed with ``EB'' are used as temporary buffers for exception handling. They are transparent registers that are automatically managed by the hart during the launch and return phases of the handling. EB0 will store the program counter (PC), while EB1 will store the status register (CSR). All EB register are WLEN bits wide and are not privileged.}

                    \item \textit{\textbf{User event handler pointer}: this register, called ``UEHP'', is used to hold the logical address of the exception handler for the current executing process. During the launching phase, UEHP will be used to perform an absolute branch (copy of UEHP value plus exception identifier into the PC). UEHP is WLEN bits wide and is not privileged.}

                    \item \textit{\textbf{Vector mask}: this register, called ``VMSK'' is used to hold the vector mask. A single bit signifies a mask for its corresponding byte of the vector result. Dedicated instructions are provided to directly set and manipulate the value of the VMSK register. The VMSK register is always WLEN bits wide and is not privileged.}

                    \item \textit{\textbf{Program counter}: this register, called ``PC'', is the program counter. It is used to point to the currently executing instruction. PC is WLEN bits wide and is not privileged.}

                    \item \textit{\textbf{Control and status register}: this register, called ``CSR'', is used to hold the hart supervisor and system state (see table below for more information). CSR is 32 bits wide and is privileged.}

                    \item \textit{\textbf{Event cause register}: this register, called ``CAUSE'', is used to hold the identifier of the latest occurring event. This register can be used inside the handler code to perform a case statement in order to execute the correct action. CAUSE is 32 bits wide and is privileged.}

                    \item \textit{\textbf{Supervisor event buffers}: registers prefixed with ``SEB'' are used as temporary buffers for supervisor event handling. They are transparent registers and are automatically managed by the CPU during the launch and return phase of the handling. SEB0 will store the program counter (PC), while SEB1 will store the status register (CSR) and SEB2 the event cause register (CAUSE). All SEB register are WLEN bits wide and are privileged.}

                    \item \textit{\textbf{Supervisor event handler pointer}: this register, called ``SEHP'', is used to hold the logical address of the supervisor event branch table. During the launching phase, SEHP will be used to perform an absolute branch (copy the value into the PC). SEHP is WLEN bits wide and is privileged.}

                    \item \textit{\textbf{Page table pointer}: this register, called ``PTP'', holds the physical address of the page tables for the current executing process. During a TLB miss, the MMU can use PTP to perform the page table walk. If the CPU transitions from user to supervisor mode, PTP must be set to point to the page tables of the OS with the use of a hardwired value. PTP is WLEN bits wide and is privileged.}

                    \item \textit{\textbf{Process identifier}: this register, called ``PID'', holds the process identifier for the currently executing process. The MMU can use PID to avoid flushing the TLB during context switches because PID serves as a discriminant. If the CPU transitions from user to supervisor mode, PID must hold the identifier of the privileged process (kernel) via the use of hardwired values. PID is WLEN bits wide and is privileged.}

                    \item \textit{\textbf{File usage}: registers prefixed with ``FU'' are used to hold information about which register in which bank was modified since the scheduling of the process. FU registers are used by specific instructions to store or load only the necessary registers for context switches. This is achieved by the use of a single bit per register to indicate if the target register is modified or not. FU0 is reserved for bank 0, FU1 for bank 1, FU2 for bank 2 and FU3 for bank 3. All FU registers are 32 bits and are privileged.}

                    \item \textit{\textbf{Kernel register}: registers prefixed with ``KR'' are kernel reserved general purpose registers. KR registers are all WLEN bits wide and are privileged.}

                \end{itemize}

                The CSR register is divided into several bits and flags fields in order to provide granular control over the supervisor mode state. If the micro-architecture doesn't support certain features, then the corresponding bits for those features can be ignored. The first 18 bits can be accessed in user mode while the remaining bits are privileged only. The bits are listed from 0 to 31 in the order that they appear:

                \begin{itemize}

                    \item \textit{\textbf{Instruction behavior section}: reserved for storing instruction behavior bits such as vector length, floating point rounding modes, etc\ldots:}

                        \begin{itemize}

                            \item \textit{\textbf{Vector length} (VLEN): six bits that indicate how many elements a vector instruction will operate on. A value of zero will signify only one element, while a value of 127 will signify all of the elements.}

                            \item \textit{\textbf{Rounding modes} (RMD): two bits that specify the floating point rounding modes:}

                                \begin{enumerate}

                                    \item \textit{round towards \(+\infty\).}
                                    \item \textit{round towards \(-\infty\).}
                                    \item \textit{round towards zero.}
                                    \item \textit{round towards even.}

                                \end{enumerate}

                            \item \textit{\textbf{Scalar mask} (SMSK): single bit that determines the mask for scalar instructions. A value of zero will allow the result to be written, while a value of one will prevent the instruction to alter any state.}

                            \item \textit{\textbf{Auto exceptions bit} (AEXC): this bit indicates if the hart should trap every time a trapping arithmetic flag is set or not.}

                        \end{itemize}

                    \item \textit{\textbf{Transactional memory section}: reserved for storing the eight bit transaction nesting depth counter (TND). Every time a transactional memory instruction is executed, this counter may be modified by either incrementing or decrementing. If the counter overflows or underflows, the OABT or UABT exceptions must be triggered accordingly.}

                    \item \textit{\textbf{Supervisor bit} (SUPB): this bit indicates if the hart is in supervisor mode or not.}

                    \item \textit{\textbf{Boot bit} (BOOT): this bit indicates if the hart is in boot mode or not.}

                    \item \textit{\textbf{Consistency bit} (CONS): this bit indicates what memory consistency model to use.}

                    \item \textit{\textbf{Paging bit} (PAGB): this bit indicates if the hart should perform address translation via paging.}

                    \item \textit{\textbf{IPC interrupts mask} (IPCM): this bit indicates if the IPC interrupts are masked or not.}

                    \item \textit{\textbf{IO interrupts mask} (IOIM): this bit indicates if the IO interrupts are masked or not.}

                    \item \textit{\textbf{Trapped bit} (TRAP): this bit indicates if the hart is currently handling a promoting event. This bit can be red by the IO controller to better understand where to route incoming interrupts.}

                    \item \textit{\textbf{Halt bit} (HLTB): this bit indicates if the hart is halted or not.}

                    \item \textit{\textbf{Cache bit} (CACB): this bit indicates if the hart can access cache or not.}

                    \item \textit{\textbf{Compatibility bit} (CPTB): this bit indicates if the hart must fault when encountering an unsupported instruction or simply execute a no-operation.}

                    \item \textit{\textbf{reserved}: the remaining bits are unused.}

                \end{itemize}

            \subsubsection{Processor operating modes}

                \vspace{10pt}

                FabRISC defines multiple operating modes specified in CSR and FR which can be changed by simply manipulating the value of said register. This is a further explanation of the above lists:

                \begin{itemize}

                    \item \textit{\textbf{Supervisor mode}: this CSR bit is automatically set by the hardware when an appropriate event is triggered and it dictates if the hart is in supervisor or user mode. For simpler implementations that don't want to support privilege levels, this can be omitted.}

                    \item \textit{\textbf{Boot mode}: this CSR bit dictates which memory device to fetch instructions from to make boot loaders possible with the help of an external ROM. For simpler implementations that don't want to support this mechanism, this bit can be omitted.}

                    \item \textit{\textbf{Consistency mode}: this CSR bit dictates the memory consistency model currently being employed and, if set, it causes the hart to execute memory instructions in program order effectively forcing the sequential consistency model. For simpler implementations that don't reorder memory instructions, this bit can be omitted.}

                    \item \textit{\textbf{Paged memory mode}: this CSR bit dictates the memory management model currently being employed and, if set, it causes the hart to perform virtual to physical translation, effectively enabling paged memory. For simpler implementations that don't support paging, this bit can be omitted.}

                    \item \textit{\textbf{Auto exceptions mode}: this CSR bit dictates the exception handling mechanism currently being employed and, if set, it causes the hart to branch to the handler whenever an exception is triggered. If the bit is not set, the hart discards any exception limiting itself to setting the flags only.}

                    \item \textit{\textbf{Cached mode}: this CSR bit dictates if a particular hart is allowed to use caches as part of it's operation. A value of zero will cause the hart to bypass the whole cache hierarchy.}

                    \item \textit{\textbf{Compatibility mode}: this CSR bit dictates the instruction compatibility mode of the current hart. A value of zero will cause the INCI fault to be triggered every time an unimplemented instruction is fetched. A value of one will bypass this and transform any unimplemented instruction into a no-operation.}

                \end{itemize}

                \vspace{10pt}

                The special purpose bank, as explained above, contains transparent debug registers which can be written with a value that is constantly being tested at every cycle. DBGM registers hold the six bit configuration code for each individual debugging register for a total of 64 possible modes. There are 16 proposed modes to help with debugging, exception handling and boundary checks. The remaining combinations are left as microarchitectural specific performance monitoring modes.

                \begin{enumerate}

                    \item \textit{\textbf{Disabled}: The value of won't be used for anything. If a DBG register is in this state, it can be used as an extra volatile GPR.}

                    \item \textit{\textbf{instruction address EQ}: Trap if an instruction with an address equal to the stored value in the corresponding DBG register is fetched. Exception code is 0B (BIAEQ).}

                    \item \textit{\textbf{instruction address LE}: Trap if an instruction with an address less or equal to the stored value in the corresponding DBG register is fetched. Exception code is 0C (BIALE).}

                    \item \textit{\textbf{instruction address GE}: Trap if an instruction with an address greater or equal to the stored value in the corresponding DBG register is fetched. Exception code is 0D (BIAGE).}

                    \item \textit{\textbf{read address EQ}: Trap if a memory read is performed at an address equal to the stored value in the corresponding DBG register. Exception code is 0E (BRAEQ).}

                    \item \textit{\textbf{read address LE}: Trap if a memory read is performed at an address less or equal to the stored value in the corresponding DBG register. Exception code is 0F (BRALE).}

                    \item \textit{\textbf{read address GE}: Trap if a memory read is performed at an address greater or equal to the stored value in the corresponding DBG register. Exception code is 10 (BRAGE).}

                    \item \textit{\textbf{write address EQ}: Trap if a memory write is performed at an address equal to the stored value in the corresponding DBG register. Exception code is 11 (BWAEQ).}

                    \item \textit{\textbf{write address LE}: Trap if a memory write is performed at an address less or equal to the stored value in the corresponding DBG register. Exception code is 12 (BWALE).}

                    \item \textit{\textbf{write address GE}: Trap if a memory write is performed at an address greater or equal to the stored value in the corresponding DBG register. Exception code is 13 (BWAGE).}

                    \item \textit{\textbf{instruction trap 16}: Trap if an instruction whose 16-bit pattern corresponds to the stored value in the corresponding DBG register is fetched. Exception code is 14 (BIN16).}

                    \item \textit{\textbf{instruction trap 32}: Trap if an instruction whose 16-bit pattern corresponds to the stored value in the corresponding DBG register is fetched. Exception code is 15 (BIN32).}

                    \item \textit{\textbf{instruction trap 48}: Trap if an instruction whose 16-bit pattern corresponds to the stored value in the corresponding DBG register is fetched. Exception code is 16 (BIN48).}

                    \item \textit{\textbf{COVR trap}: Trap if an instruction whose address corresponds to the stored value in the corresponding DBG register generates a COVR flag. Exception code is 17 (BCOVR).}

                    \item \textit{\textbf{CUND trap}: Trap if an instruction whose address corresponds to the stored value in the corresponding DBG register generates a CUND flag. Exception code is 18 (BCUND).}

                    \item \textit{\textbf{OVFL trap}: Trap if an instruction whose address corresponds to the stored value in the corresponding DBG register generates a OVFL flag. Exception code is 19 (BOVFL).}

                    \item \textit{\textbf{UNFL trap}: Trap if an instruction whose address corresponds to the stored value in the corresponding DBG register generates a UNFL flag. Exception code is 1A (BUNFL).}

                    \item \textit{\textbf{DIV0 trap}: Trap if an instruction whose address corresponds to the stored value in the corresponding DBG register generates a DIV0 flag. Exception code is 1B (BDIV0).}

                \end{enumerate}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{The entirety of the register file is divided into three banks with several registers each. This can sound like a lot of state (and it kinda is), but other ISAs such as full RISC-V implementation would arguably contain more because of the way CSRs are implemented. In FabRISC, the first bank offers a 32 entry flat register file in order to efficiently support modern graph-coloring driven compiler register allocation. Integer and floating-point registers are shared to ease conversions and the extra GPRs found in the special purpose bank can alleviate some of the pressure caused by the sharing. Because there is no hardware stack pointer nor return address register, standard calling conventions can be used to give a ``purpose'' to all the GPRs in the bank. Compressed instructions, because of the size limitations, are only able to access eight registers of the bank. The second bank is where the ``magic'' happens: special registers are present to help with debugging, memory safety as well as keeping track of state and resource usage to reduce the overhead on context switches. File usage registers help with that, for example, if no vector register was written during the time quantum of a particular process, then there is no need to save them again.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Instruction formats}

            \vspace{10pt}

            FabRISC specifies 15 different instruction formats to allocate as much space as possible to the operands, while leaving some opcode encoding space to implement extra application specific instructions. Formats can be variable length from two up to six bytes in order to accommodate larger immediate constants for addresses and data. Formats are divided into several bit fields that are scrambled around in order to reduce decoding logic. Many also carry with them a ``modifier'' field, called mod, that can provide extra information such as mask, data type length, vector mode and more. All instructions treat data as signed unless explicitly noted.

            \vspace{10pt}
            \input{./Tables/Formats.tex}
            \vspace{10pt}

            \begin{itemize}

                \item \textit{\textbf{opc}: short for instruction opcode.}
                \item \textit{\textbf{mod}: short for instruction modifier.}
                \item \textit{\textbf{ra, rb, rc, rd}: short for register a, b, c, d which are register specifiers.}
                \item \textit{\textbf{imm}: short for immediate.}

            \end{itemize}

            The instruction modifier bit field depends on the particular class of instructions in question. Each format can have different modifier classes to best fit particular groups of instructions:

            \begin{itemize}

                \item \textit{\textbf{A}: this format has three instruction modifier classes:}

                    \begin{enumerate}

                        \item \textit{\textbf{tt m vv}: this class is used by scalar computational instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes, 'm' states if the instruction is masked or not and 'vv' indicates the instruction mode: scalar, vector-vector or vector-scalar.}

                        \item \textit{\textbf{tt m --}: this class is used by vector gather and scatter instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes and 'm' states if the instruction is masked or not.}

                        \item \textit{\textbf{tt m ff}: this class is used by the CAS instruction. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes, 'm' states if the instruction is masked or not and 'ff' states the condition to check: EQ, NE, LT or LE.}

                    \end{enumerate}

                \item \textit{\textbf{B and B.l}: this format has one instruction modifier class:}

                    \begin{enumerate}

                        \item \textit{\textbf{tt m v}: this class is used by scalar and vector computational instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes, 'm' states if the instruction is masked or not and 'v' indicates the instruction mode: scalar or vector-scalar.}

                    \end{enumerate}

                \item \textit{\textbf{C}: this format has four instruction modifier classes:}

                    \begin{enumerate}

                        \item \textit{\textbf{tt m ---}: this class is used by scalar computational instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes and 'm' states if the instruction is masked or not.}

                        \item \textit{\textbf{tt m - tt}: this class is used by casts and conversion instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes, 'm' states if the instruction is masked or not.}

                        \item \textit{\textbf{tt m nnn}: this class is used by move and swap multiple instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes, 'm' states if the instruction is masked or not and 'nnn' specifies how many registers are acted on, from one to eight inclusive.}

                        \item \textit{\textbf{tt m s ff}: this class is used by mask setting on compare instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes, 'm' states if the instruction is masked or not, 's' states if the instruction operates on signed or unsigned data and 'ff' states the condition to check: EQ, NE, LT or LE.}

                    \end{enumerate}

                \item \textit{\textbf{D and E}: these formats have two instruction modifier classes:}

                    \begin{enumerate}

                        \item \textit{\textbf{tt m}: this class is used by scalar memory instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes and 'm' states if the instruction is masked or not.}

                        \item \textit{\textbf{- m a}: this class is used by vector memory instructions. 'a' encodes the addressing mode: standard or striding and 'm' states if the instruction is masked or not.}

                    \end{enumerate}

                \item \textit{\textbf{D.l, E.l and F}: these formats have two instruction modifier classes:}

                    \begin{enumerate}

                        \item \textit{\textbf{tt m uu}: this class is used by scalar memory instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes, 'm' states if the instruction is masked or not and 'uu' specifies what auto update mode to use: nothing, post-increment, post-decrement or pre-decrement.}

                        \item \textit{\textbf{-- m a uu}: this class is used by vector memory instructions. 'a' encodes the addressing mode: standard or striding, 'm' states if the instruction is masked or not and 'uu' specifies what auto update mode to use: nothing, post-increment, post-decrement or pre-decrement.}

                    \end{enumerate}

                \item \textit{\textbf{G and G.l}: this format has four instruction modifier classes:}

                    \begin{enumerate}

                        \item \textit{\textbf{rr m -}: this class is used by block memory instructions. 'rr' specifies which register file: SGPRs, SPRs or VGPRs and 'm' states if the instruction is masked or not}

                        \item \textit{\textbf{ff p -}: this class is used by test branch instructions. 'ff' specifies the condition: EQ, NE, LT or LE and 'p' states if the instruction mode: integer or floating point.}

                        \item \textit{\textbf{iiii}: this class is used by direct function calls and jump instructions. 'iiii' extends the offset by four bits.}

                        \item \textit{\textbf{e h m s}: this class is used by special bit-field manipulation instructions. 'e' specifies how the immediate is filled: zero-filled or one-filled. 'h' specifies the immediate highlighting mode: zeros ignore and ones select or zero clear and ones select. 'm' states if the instruction is masked or not and 's' signifies if the immediate is shifted by 32 positions to the left or not.}

                    \end{enumerate}

                \item \textit{\textbf{H}: this format has one instruction modifier class:}

                    \begin{enumerate}

                        \item \textit{\textbf{tt p}: this class is used by compressed computational instructions. 'tt' encodes the data type length: 1, 2, 4 or 8 bytes and 'p' states if the instruction mode: integer or floating point.}

                    \end{enumerate}

            \end{itemize}

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{The moderate number of formats arise from the fact that i wanted to ``best-fit'' several groups of instructions in order to leave as much space as possible to the operands without hindering the opcode space. I believe, however, that the decoding complexity is still very manageable due to the high degree of similarity among the formats. Some times is just a few bits changing purpose and or position. The register specifiers are always in the same position and the MSB of immediates are also always in the same position to reduce decoding complexity. The first seven bits, although sometimes not enough for the full opcode, will always be enough to encode the format and, therefore, the length of the instruction.}
        \par\noindent\rule{\textwidth}{0.4pt}

        \subsection{Decoding guidelines}    % FINISH <<<<<<<<<<<<<<<<<<

            \vspace{10pt}

            This sub section is dedicated to give hints and suggestions to how to decode instructions for this particular ISA. It is important to remember that this is only a suggestion and it's not mandatory to strictly perform the decoding in the presented manner. Nevertheless, the proposed decoding strategy for a one instruction is divided into multiple steps:

            \begin{enumerate}

                \item \textit{retrieve the opcode.}
                \item \textit{use the retrieved opcode to index the microcode read only memory.}
                \item \textit{use some of the microcode output to route the operand fields.}
                \item \textit{use some of the microcode output to insert the correct operation codes.}
                \item \textit{emit the composed micro-instruction.}

            \end{enumerate}

            The micro-instruction is supposed to be a more ``digested'' macro-instruction that is much more hardware friendly while still retaining some information density in order to reduce it's size. The micro-instruction can be further decoded down the pipeline to extract the raw control lines for the individual functional units.

            \subsubsection{Opcode extraction}

                \vspace{10pt}

                Instruction opcodes can be of variable length of 7, 8, 12 and 16 bits. The length of the opcode can be retrieved by looking at the first 7 seven bits. From there, with the help of a hard coded logic array, the full opcode can be obtained. Once fully composed, the opcode can then be used to index into the microcode ROM where information such as the format is held. Opcodes are distributed in the following manner:

                \begin{itemize}

                    \item \textit{\textbf{7 bits} 0000000xxxxxxxxx $\rightarrow$ 1011011xxxxxxxxx with a total of 92 combinations.}
                    \item \textit{\textbf{8 bits} 10111000xxxxxxxx $\rightarrow$ 11110111xxxxxxxx with a total of 64 combinations.}
                    \item \textit{\textbf{12 bits} 111110000000xxxx $\rightarrow$ 111110111111xxxx with a total of 64 combinations.}
                    \item \textit{\textbf{16 bits} 1111110000000000 $\rightarrow$ 1111110001111111 with a total of 128 combinations.}

                \end{itemize}

                The total size of the encoding space amounts to 348 instructions, however, only xxx opcodes are used in total. It's possible to reserve one entry in the microcode ROM for each possible instruction but opcodes are assigned in a specific way to reduce the size of the ROM. Instructions that fundamentally perform the same operation but on different data types such as integer and floating point will map to the same entry, compressing the encoding space to just under 256 entries. This compression requires a hard coded logic array that composes the target 8 bit ROM address. Some instructions might require some form of sequencing which can be achieved by either emitting multiple micro-instructions or letting the target functional unit handle the sequencing. It's important to note that the sequencing required is very simple because the instructions that need it effectively perform the same operation but multiple times, for example: block moves simply copy multiple registers. If it's decided to sequence the actual microcode, then the remaining entries of the ROM can be used for that very purpose.

                [opcode compression table here...]

            \subsubsection{Micro-operation format}

                Micro-operation formats should be few with regular and easy to decode fields. Having one format with fixed length will simplify the logic that handles the micro-op at the cost of more space required to store it. Variable length formats can be an good choice to increase density, especially in the micro-op cache at the cost of more complex logic. Finding a good balance is can get tricky, but the following fixed length format can be a good starting point:

                ...

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{The most expensive part of the decoding process is the micro-code ROM, which is going to roughly be 1024 bytes assuming a 32 bit entries. This might seem a lot, but most FPGAs have dedicated memory blocks that can cover the needed size. Block rams are quite fast and are often multi-ported to allow simultaneous access from different locations. This means that one block-ram is enough even for super-scalar micro-architectures where multiple instructions are decoded in parallel. The micro-instruction is the result of the decoding process, which holds all the information needed for later steps such as register and operation specifiers as well as other control signals all in one single object. As mentioned above, complex instructions might need to be ``unrolled'' or expanded into more than one micro-instruction before the processor advances to the next macro-instruction.}
        \par\noindent\rule{\textwidth}{0.4pt}

    \clearpage

%__________________________________________________________________________________________________________________________________

    \section[Instruction list]{\LARGE\underline{Instruction list}} %7

        \vspace{10pt}

        This section is dedicated to a full and extensive list of all the proposed instructions in the ISA which are divided into their corresponding macro module and micro module. Each micro module will list its instructions in alphabetical order.

        \subsection{Basic scalar integer computational}

            \vspace{10pt}

            This subsection is dedicated to simple scalar integer computational instructions. This module has the code name ``BSIC`` (basic scalar integer computational) and includes simple arithmetic and logic integer operations.

            \subsubsection{(ADD) Addition}

                This instruction computes \(ra = rb + rc\). ADD is unprivileged; has an opcode of xxx and belongs to the A format. Updated arithmetic flags are the following: COVR, CUND, OVFL, UNFL, ZERO and SIGN. The remaining arithmetic flags are reset to zero. The applied modifier class is 1.

            \par\noindent\rule{\textwidth}{0.4pt}

            \subsubsection{(SUB) Subtraction}

                This instruction computes \(ra = rb - rc\). SUB is unprivileged; has an opcode of xxx and belongs to the A format. Updated arithmetic flags are the following: COVR, CUND, OVFL, UNFL, ZERO and SIGN. The remaining arithmetic flags are reset to zero. The applied modifier class is 1.

            \par\noindent\rule{\textwidth}{0.4pt}

            [to be continued...]

        \subsection{Data transfer instructions}

            [Coming soon...]

        \subsection{Control transfer instructions}

            [Coming soon...]

        \subsection{System instructions}

            [Coming soon...]

    \clearpage

%__________________________________________________________________________________________________________________________________

    \section[Macro-op fusion]{Macro-op fusion}

        \vspace{10pt}

        This section is dedicated to give a brief explanation of the macro-op fusion technique. Macro-op fusion can help to increase performance by combining common instruction idioms, usually just pairs of instructions, into one micro-op that can be executed in a single cycle by the back-end of the processor. A fixed and hard-coded set of fusible instruction sequences is needed to tell the hardware when the fusion is applicable and when it is not, however, the only constraint is that a fused sequence must behave in the same way as a non fused sequence of the same instructions. In short, breaking a fusible sequence with a NOP or other non fusible instruction should not yield different architectural states. Some sequences are listed below, but more are possible:

        \begin{enumerate}

            \item ...

        \end{enumerate}

        [to be continued...]

        \par\noindent\rule{\textwidth}{0.4pt}
        \textit{This is a very interesting technique that can help improve performance, especially in cases where the hardware is capable of doing certain operations in one cycle, but the ISA can't. The instruction decoder, though, needs to be designed with this capability in mind and the use of a micro-op cache greatly helps minimizing the pipeline bubbles created by the fusion. The micro-op cache also helps reducing power because it stores decoded instructions avoiding re decoding them every time the same code is executed. Fetching branches from this cache reduces their penalty in case of incorrect prediction.}
        \par\noindent\rule{\textwidth}{0.4pt}

    \clearpage

%__________________________________________________________________________________________________________________________________

    \section[License]{License}

        \vspace{10pt}

        Official GitHub page of the FabRISC project: ...

        \vspace{10pt}

        This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. For more information, please visit \textit{creativecommons.org/licenses/by-sa/4.0/}

        \begin{figure}[hbt!]

            \includegraphics[scale = 0.8]{./Images/LICENSE.png}
            \label{fig:LICENSE}
        
        \end{figure}

    \clearpage

\end{document}
%__________________________________________________________________________________________________________________________________
